{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e1a8a2",
   "metadata": {},
   "source": [
    "# SEIR Model, LHS Sampling, and Surrogate Training with LSTM & GRU\n",
    "\n",
    "In this notebook we simulate an age‐structured SEIR model for infectious disease dynamics, explore the parameter space using Latin Hypercube Sampling (LHS), and train surrogate models using Recurrent Neural Networks (RNNs) – specifically, Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) architectures.\n",
    "\n",
    "The notebook is divided into several sections:\n",
    "\n",
    "1. **Infectious Disease Modelling Theory:** An introduction to compartmental models such as SEIR.\n",
    "2. **Surrogate Models:** Why we build surrogates and how they enable rapid approximation of expensive simulations.\n",
    "3. **RNNs for Time Series Prediction:** An overview of RNNs with a focus on LSTM and GRU cells, including the relevant mathematics.\n",
    "4. **Simulation, Parameter Sampling and Surrogate Training:** Code sections for the SEIR model, LHS sampling, and training of surrogate models.\n",
    "\n",
    "Let’s get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d55cf5",
   "metadata": {},
   "source": [
    "## 1. Infectious Disease (ID) Modelling Theory\n",
    "\n",
    "Infectious disease modelling is a key tool for understanding and predicting the spread of diseases in populations. One common approach is to use **compartmental models**. In these models, the population is divided into distinct groups (or compartments) based on disease status. \n",
    "\n",
    "### The SEIR Model\n",
    "\n",
    "The SEIR model is one of the most widely used compartmental models. It divides the population into:\n",
    "\n",
    "- **S (Susceptible):** Individuals who can contract the disease.\n",
    "- **E (Exposed):** Individuals who have been infected but are not yet infectious.\n",
    "- **I (Infectious):** Individuals who can transmit the disease to others.\n",
    "- **R (Recovered):** Individuals who have recovered and may have immunity.\n",
    "\n",
    "An additional compartment, **C (Cumulative incidence)**, is sometimes added to keep track of the total number of new infections. \n",
    "\n",
    "The dynamics of these compartments are usually described by a system of differential equations. In our model, we further **stratify by age** (17 age groups) to capture heterogeneous mixing patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c1d8d1",
   "metadata": {},
   "source": [
    "## 2. Surrogate Models and RNNs\n",
    "\n",
    "### Why Surrogate Models?\n",
    "\n",
    "High-fidelity simulations (such as our SEIR model) can be computationally expensive, especially when exploring large parameter spaces. **Surrogate models** are fast, approximate models that are trained to emulate the output of these expensive simulations. They allow rapid predictions, uncertainty quantification, and real-time decision support.\n",
    "\n",
    "### Recurrent Neural Networks (RNNs)\n",
    "\n",
    "RNNs are designed for sequential data (e.g., time series) by maintaining a hidden state that carries information from previous time steps. Two popular RNN architectures are **LSTM (Long Short-Term Memory)** and **GRU (Gated Recurrent Unit)**. \n",
    "\n",
    "#### LSTM Equations\n",
    "\n",
    "The LSTM cell updates are given by:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "i_t &= \\sigma(W_{xi} x_t + W_{hi} h_{t-1} + b_i) \\\\\n",
    "f_t &= \\sigma(W_{xf} x_t + W_{hf} h_{t-1} + b_f) \\\\\n",
    "o_t &= \\sigma(W_{xo} x_t + W_{ho} h_{t-1} + b_o) \\\\\n",
    "\\tilde{c}_t &= \\tanh(W_{xc} x_t + W_{hc} h_{t-1} + b_c) \\\\\n",
    "c_t &= f_t \\odot c_{t-1} + i_t \\odot \\tilde{c}_t \\\\\n",
    "h_t &= o_t \\odot \\tanh(c_t) \n",
    "\\end{aligned}$$\n",
    "\n",
    "Here, $i_t$, $f_t$, and $o_t$ are the input, forget, and output gates respectively, and $c_t$ is the cell state.\n",
    "\n",
    "#### GRU Equations\n",
    "\n",
    "The GRU cell updates are somewhat simpler:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "z_t &= \\sigma(W_{xz} x_t + W_{hz} h_{t-1} + b_z) \\\\\n",
    "r_t &= \\sigma(W_{xr} x_t + W_{hr} h_{t-1} + b_r) \\\\\n",
    "\\tilde{h}_t &= \\tanh(W_{xh} x_t + r_t \\odot (W_{hh} h_{t-1}) + b_h) \\\\\n",
    "h_t &= (1 - z_t) \\odot h_{t-1} + z_t \\odot \\tilde{h}_t\n",
    "\\end{aligned}$$\n",
    "\n",
    "These mechanisms allow the network to capture long-term dependencies and selectively forget or update information.\n",
    "\n",
    "### What Does the Surrogate Do?\n",
    "\n",
    "In our setting, the surrogate model (using either LSTM or GRU) takes as input a sequence that includes:\n",
    "\n",
    "- A normalized time feature.\n",
    "- A set of simulation parameters (e.g. latent period, infectious period, etc.) repeated at each time step.\n",
    "\n",
    "It then predicts the time series output (e.g., total incidence over time) that would be produced by the full SEIR simulation. By training on many simulation runs, the surrogate learns to approximate the mapping from parameters to outcomes very quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e733e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------- #\n",
    "# 1. Load in packages\n",
    "# -------------------------------------------------------- #\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import eigvals\n",
    "import pandas as pd\n",
    "\n",
    "# Use inline plotting for Jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------- #\n",
    "# 2. SEIR Model Definition\n",
    "# -------------------------------------------------------- #\n",
    "\n",
    "class SEIR:\n",
    "    \"\"\"\n",
    "    A class for simulating a deterministic age‐structured SEIR model with 17 age groups.\n",
    "    \n",
    "    Compartments per age group:\n",
    "      - S: Susceptible\n",
    "      - E: Exposed (infected but not yet infectious)\n",
    "      - I: Infectious\n",
    "      - R: Recovered\n",
    "      - C: Cumulative incidence (number of new infections entering I)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        contact_matrix,\n",
    "        latent_period,\n",
    "        infectious_period,\n",
    "        immunity_period, \n",
    "        N,\n",
    "        I0,\n",
    "        seed=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialise the model with user‐provided parameters.\n",
    "        \"\"\"\n",
    "        self.n_age = 17\n",
    "        self.contact_matrix = np.array(contact_matrix)\n",
    "\n",
    "        self.latent_period = latent_period\n",
    "        self.infectious_period = infectious_period\n",
    "        self.immunity_period = immunity_period\n",
    "        self.sigma = 1.0 / latent_period      # rate of leaving the exposed compartment\n",
    "        self.gamma = 1.0 / infectious_period  # recovery rate\n",
    "        self.rho = 1.0 / immunity_period      # rate of loss of immunity\n",
    "\n",
    "        N = np.array(N)\n",
    "        if N.shape[0] != self.n_age:\n",
    "            raise ValueError(f\"N must be of length {self.n_age}.\")\n",
    "\n",
    "        # Allocate I0 infections among age groups 20-60 (indices 4 to 11)\n",
    "        eligible_indices = np.arange(4, 12)\n",
    "        I_init = np.zeros(self.n_age, dtype=int)\n",
    "        rng = np.random.default_rng(seed)\n",
    "        if I0 > 0:\n",
    "            allocation = rng.multinomial(I0, np.full(len(eligible_indices), 1/len(eligible_indices)))\n",
    "            I_init[eligible_indices] = allocation\n",
    "\n",
    "        S_init = N - I_init\n",
    "        if np.any(S_init < 0):\n",
    "            raise ValueError(\"Allocated initial infections exceed population in one or more groups.\")\n",
    "\n",
    "        E_init = np.zeros(self.n_age, dtype=int)\n",
    "        R_init = np.zeros(self.n_age, dtype=int)\n",
    "\n",
    "        self.initial_conditions = {\n",
    "            'S': S_init.astype(float),\n",
    "            'E': E_init.astype(float),\n",
    "            'I': I_init.astype(float),\n",
    "            'R': R_init.astype(float)\n",
    "        }\n",
    "\n",
    "        self.pop_age = S_init + E_init + I_init + R_init\n",
    "\n",
    "        self.initial_C = np.zeros(self.n_age)\n",
    "        self.y0 = np.concatenate([\n",
    "            self.initial_conditions['S'],\n",
    "            self.initial_conditions['E'],\n",
    "            self.initial_conditions['I'],\n",
    "            self.initial_conditions['R'],\n",
    "            self.initial_C\n",
    "        ])\n",
    "\n",
    "        eigenvalues = eigvals(self.contact_matrix)\n",
    "        self.denom = np.max(np.abs(eigenvalues))\n",
    "\n",
    "        self.results = None\n",
    "\n",
    "    def get_current_Rt(self, t):\n",
    "        if t < self.tt_Rt[1]:\n",
    "            return self.Rt[0]\n",
    "        elif t < self.tt_Rt[2]:\n",
    "            return self.Rt[1]\n",
    "        else:\n",
    "            return self.Rt[2]\n",
    "\n",
    "    def beta_t(self, t):\n",
    "        current_Rt = self.get_current_Rt(t)\n",
    "        return current_Rt / (self.infectious_period * self.denom)\n",
    "\n",
    "    def deriv(self, t, y):\n",
    "        S = y[0:self.n_age]\n",
    "        E = y[self.n_age:2*self.n_age]\n",
    "        I = y[2*self.n_age:3*self.n_age]\n",
    "        R = y[3*self.n_age:4*self.n_age]\n",
    "        C = y[4*self.n_age:5*self.n_age]\n",
    "\n",
    "        beta = self.beta_t(t)\n",
    "        lambda_vec = beta * np.dot(self.contact_matrix, I / self.pop_age)\n",
    "\n",
    "        dS = -lambda_vec * S + self.rho * R\n",
    "        dE = lambda_vec * S - self.sigma * E\n",
    "        dI = self.sigma * E - self.gamma * I\n",
    "        dR = self.gamma * I - self.rho * R\n",
    "        dC = self.sigma * E\n",
    "\n",
    "        return np.concatenate([dS, dE, dI, dR, dC])\n",
    "\n",
    "    def run(self, t_end, Rt, tt_Rt, dt=0.1):\n",
    "        self.Rt = np.array(Rt)\n",
    "        self.tt_Rt = np.array(tt_Rt)\n",
    "        if len(self.Rt) != 3 or len(self.tt_Rt) != 3:\n",
    "            raise ValueError(\"Rt and tt_Rt must be of length 3.\")\n",
    "\n",
    "        t_eval = np.arange(0, t_end, dt)\n",
    "        sol = solve_ivp(self.deriv, [0, t_end], self.y0, t_eval=t_eval, vectorized=False)\n",
    "        if not sol.success:\n",
    "            raise RuntimeError(\"Integration failed.\")\n",
    "        self.results = sol\n",
    "        return sol\n",
    "\n",
    "    def get_output(self):\n",
    "        if self.results is None:\n",
    "            raise RuntimeError(\"No simulation results available. Run the simulation first.\")\n",
    "\n",
    "        t_all = self.results.t\n",
    "        int_days = np.floor(t_all).astype(int)\n",
    "        unique_days = np.unique(int_days)\n",
    "        indices = []\n",
    "        for day in unique_days:\n",
    "            idx_day = np.where(int_days == day)[0]\n",
    "            indices.append(idx_day[-1])\n",
    "        indices = np.array(indices)\n",
    "\n",
    "        S_int = self.results.y[0:self.n_age, :][:, indices].T\n",
    "        E_int = self.results.y[self.n_age:2*self.n_age, :][:, indices].T\n",
    "        I_int = self.results.y[2*self.n_age:3*self.n_age, :][:, indices].T\n",
    "        R_int = self.results.y[3*self.n_age:4*self.n_age, :][:, indices].T\n",
    "        C_int = self.results.y[4*self.n_age:5*self.n_age, :][:, indices].T\n",
    "\n",
    "        incidence_age = np.vstack([np.zeros((1, self.n_age)), np.diff(C_int, axis=0)])\n",
    "        total_incidence = incidence_age.sum(axis=1)\n",
    "\n",
    "        output = {\n",
    "            'time': unique_days,\n",
    "            'S': S_int,\n",
    "            'E': E_int,\n",
    "            'I': I_int,\n",
    "            'R': R_int,\n",
    "            'C': C_int,\n",
    "            'incidence_age': incidence_age,\n",
    "            'total_incidence': total_incidence\n",
    "        }\n",
    "        return output\n",
    "\n",
    "    def plot_output(self):\n",
    "        output = self.get_output()\n",
    "        t = output['time']\n",
    "        S_total = output['S'].sum(axis=1)\n",
    "        E_total = output['E'].sum(axis=1)\n",
    "        I_total = output['I'].sum(axis=1)\n",
    "        R_total = output['R'].sum(axis=1)\n",
    "        total_incidence = output['total_incidence']\n",
    "\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "        axs[0].plot(t, S_total, label='Susceptible')\n",
    "        axs[0].plot(t, E_total, label='Exposed')\n",
    "        axs[0].plot(t, I_total, label='Infectious')\n",
    "        axs[0].plot(t, R_total, label='Recovered')\n",
    "        axs[0].set_xlabel('Time (days)')\n",
    "        axs[0].set_ylabel('Number of individuals')\n",
    "        axs[0].set_title('SEIR Model Compartments (Aggregated by Day)')\n",
    "        axs[0].legend()\n",
    "\n",
    "        axs[1].plot(t, total_incidence, label='Incidence', color='red')\n",
    "        axs[1].set_xlabel('Time (days)')\n",
    "        axs[1].set_ylabel('New infections per day')\n",
    "        axs[1].set_title('Daily Incidence of Infections')\n",
    "        axs[1].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3a4c0b",
   "metadata": {},
   "source": [
    "## 3. Demo: Running the SEIR Model\n",
    "\n",
    "Below we load in the contact matrix and age distribution data (make sure the files `data/seir_contact_matrix.csv` and `data/sa_ages.csv` are available) and run the SEIR simulation. We then plot the aggregated compartments and compare the simulation output with external data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d52c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------- #\n",
    "# 3. Demo SEIR\n",
    "# -------------------------------------------------------- #\n",
    "\n",
    "n_age = 17\n",
    "\n",
    "# Read in contact matrix and age distribution\n",
    "contact_matrix = pd.read_csv(\"data/seir_contact_matrix.csv\").values\n",
    "N = pd.read_csv(\"data/sa_ages.csv\").n.values\n",
    "\n",
    "latent_period = 5.0\n",
    "infectious_period = 7.0\n",
    "immunity_period = 365\n",
    "\n",
    "I0 = 20\n",
    "\n",
    "Rt = [3, 0.9, 1.8]\n",
    "tt_Rt = [0, 90, 180]\n",
    "\n",
    "model = SEIR(contact_matrix, latent_period, infectious_period, immunity_period, N, I0, seed=42)\n",
    "\n",
    "model.run(t_end=730, Rt=Rt, tt_Rt=tt_Rt, dt=0.1)\n",
    "\n",
    "model.plot_output()\n",
    "\n",
    "dat = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mrc-ide/global-lmic-reports/refs/heads/main/ZAF/2022-06-20/projections.csv\"\n",
    ")\n",
    "dat[\"date\"] = pd.to_datetime(dat[\"date\"])\n",
    "dat[\"t\"] = (dat[\"date\"] - dat[\"date\"].min()).dt.days\n",
    "dat[\"t\"] = dat[\"t\"].astype(int)\n",
    "\n",
    "model.plot_output()\n",
    "plt.plot(\n",
    "    dat.loc[(dat[\"compartment\"] == \"infections\") \n",
    "            & (dat[\"scenario\"] == \"Maintain Status Quo\") \n",
    "            & (dat[\"t\"] >= 110) \n",
    "            & (dat[\"t\"] <= 730 + 110), \"t\"] - 110,\n",
    "    dat.loc[(dat[\"compartment\"] == \"infections\") \n",
    "            & (dat[\"scenario\"] == \"Maintain Status Quo\") \n",
    "            & (dat[\"t\"] >= 110) \n",
    "            & (dat[\"t\"] <= 730 + 110), \"y_median\"],\n",
    "    label='External Data'\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d1864e",
   "metadata": {},
   "source": [
    "## 4. Latin Hypercube Sampling (LHS) for Parameter Exploration\n",
    "\n",
    "Latin Hypercube Sampling (LHS) is a statistical method that efficiently explores a high-dimensional parameter space. In our model, we sample parameters such as the latent period, infectious period, immunity duration, reproduction numbers, and switching times. \n",
    "\n",
    "This approach helps us generate diverse simulation runs so that the surrogate model can be trained on a wide range of scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8f8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------- #\n",
    "# 4. LHS\n",
    "# -------------------------------------------------------- #\n",
    "\n",
    "from scipy.stats import qmc\n",
    "\n",
    "def sample_parameter_sets(\n",
    "    n_samples, latent_range, infectious_range, immunity_range, Rt_range, tt_Rt_range, seed=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Sample parameter sets using Latin Hypercube Sampling.\n",
    "    \"\"\"\n",
    "    n_params = 9\n",
    "    sampler = qmc.LatinHypercube(d=n_params, seed=seed)\n",
    "    sample_unit = sampler.random(n=n_samples)\n",
    "\n",
    "    latent_samples = latent_range[0] + sample_unit[:, 0] * (latent_range[1] - latent_range[0])\n",
    "    infectious_samples = infectious_range[0] + sample_unit[:, 1] * (infectious_range[1] - infectious_range[0])\n",
    "    immunity_samples = immunity_range[0] + sample_unit[:, 2] * (immunity_range[1] - immunity_range[0])\n",
    "\n",
    "    Rt_samples = []\n",
    "    for i in range(3):\n",
    "        col = 3 + i\n",
    "        Rt_samples.append(Rt_range[0] + sample_unit[:, col] * (Rt_range[1] - Rt_range[0]))\n",
    "    Rt_samples = np.column_stack(Rt_samples)\n",
    "\n",
    "    tt_Rt_samples = []\n",
    "    for i in range(3):\n",
    "        col = 6 + i\n",
    "        tt_Rt_samples.append(tt_Rt_range[0] + sample_unit[:, col] * (tt_Rt_range[1] - tt_Rt_range[0]))\n",
    "    tt_Rt_samples = np.column_stack(tt_Rt_samples)\n",
    "\n",
    "    parameter_sets = []\n",
    "    for i in range(n_samples):\n",
    "        params = {\n",
    "            \"latent_period\": latent_samples[i],\n",
    "            \"infectious_period\": infectious_samples[i],\n",
    "            \"immunity_period\": immunity_samples[i],\n",
    "            \"Rt\": list(Rt_samples[i, :]),\n",
    "            \"tt_Rt\": sorted(list(tt_Rt_samples[i, :]))\n",
    "        }\n",
    "        parameter_sets.append(params)\n",
    "\n",
    "    return parameter_sets\n",
    "\n",
    "def sample_and_run_models(\n",
    "    n_samples,\n",
    "    contact_matrix,\n",
    "    N,\n",
    "    I0,\n",
    "    t_end,\n",
    "    latent_range,\n",
    "    infectious_range,\n",
    "    immunity_range,\n",
    "    Rt_range,\n",
    "    tt_Rt_range,\n",
    "    dt=0.1,\n",
    "    seed=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Sample parameter sets using LHS and run the SEIR model for each set.\n",
    "    \"\"\"\n",
    "    parameter_sets = sample_parameter_sets(\n",
    "        n_samples, latent_range, infectious_range, immunity_range, Rt_range, tt_Rt_range, seed=seed\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    for params in parameter_sets:\n",
    "        model = SEIR(\n",
    "            contact_matrix,\n",
    "            params[\"latent_period\"],\n",
    "            params[\"infectious_period\"],\n",
    "            params[\"immunity_period\"],\n",
    "            N,\n",
    "            I0,\n",
    "            seed=seed,\n",
    "        )\n",
    "        model.run(t_end=t_end, Rt=params[\"Rt\"], tt_Rt=params[\"tt_Rt\"], dt=dt)\n",
    "        output = model.get_output()\n",
    "        results.append((params, output))\n",
    "\n",
    "    return results\n",
    "\n",
    "def plot_sampled_results(sampled_results):\n",
    "    \"\"\"\n",
    "    Plot the simulation outputs for multiple sampled runs.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for i, (params, output) in enumerate(sampled_results):\n",
    "        t = output[\"time\"]\n",
    "        total_incidence = output[\"total_incidence\"]\n",
    "        label_str = (\n",
    "            f\"latent={params['latent_period']:.2f}, \"\n",
    "            f\"inf={params['infectious_period']:.2f}, \"\n",
    "            f\"imm={params['immunity_period']:.0f}, \"\n",
    "            f\"Rt=[{params['Rt'][0]:.2f}, {params['Rt'][1]:.2f}, {params['Rt'][2]:.2f}], \"\n",
    "            f\"tt_Rt=[{params['tt_Rt'][0]:.0f}, {params['tt_Rt'][1]:.0f}, {params['tt_Rt'][2]:.0f}]\"\n",
    "        )\n",
    "        plt.plot(t, total_incidence, label=label_str)\n",
    "\n",
    "    plt.xlabel(\"Time (days)\")\n",
    "    plt.ylabel(\"Daily Total Incidence\")\n",
    "    plt.title(\"Daily Total Incidence for Sampled Parameter Sets\")\n",
    "    plt.legend(fontsize=\"small\", loc=\"upper right\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# LHS Demo\n",
    "\n",
    "latent_range = (2.0, 4.0)\n",
    "infectious_range = (4.0, 7.0)\n",
    "immunity_range = (365*1.5, 365*1.5)\n",
    "Rt_range = (0.5, 4.0)\n",
    "tt_Rt_range = (50, 200)\n",
    "\n",
    "n_samples = 5\n",
    "\n",
    "sampled_results = sample_and_run_models(\n",
    "    n_samples,\n",
    "    contact_matrix,\n",
    "    N,\n",
    "    I0,\n",
    "    t_end=730,\n",
    "    latent_range=latent_range,\n",
    "    infectious_range=infectious_range,\n",
    "    immunity_range=immunity_range,\n",
    "    Rt_range=Rt_range,\n",
    "    tt_Rt_range=tt_Rt_range,\n",
    "    dt=0.1,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "for i, (params, output) in enumerate(sampled_results):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(\"Parameters:\")\n",
    "    print(params)\n",
    "    print(\"Total incidence on final day:\", output[\"total_incidence\"][-1])\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "plot_sampled_results(sampled_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d7df2",
   "metadata": {},
   "source": [
    "## 5. Surrogate Training with LSTM and GRU\n",
    "\n",
    "In the final section we build surrogate models to emulate the output of the SEIR simulation. \n",
    "\n",
    "### Dataset and Scaling\n",
    "\n",
    "We first construct a custom PyTorch dataset that for each simulation run produces an input sequence `X` of shape `(T, 1+9)`:\n",
    "\n",
    "- The **first column** is a normalized time feature (values between 0 and 1).\n",
    "- The **remaining columns** are the simulation parameters (latent period, infectious period, immunity period, Rt values, and switching times) repeated over all time steps. \n",
    "\n",
    "The target `Y` is the time series of total incidence (per day). Both inputs and targets are scaled using `StandardScaler`.\n",
    "\n",
    "### LSTM and GRU Models\n",
    "\n",
    "We define two architectures:\n",
    "\n",
    "- **LSTM Model:** Uses LSTM cells as described earlier.\n",
    "- **GRU Model:** Uses GRU cells.\n",
    "\n",
    "The surrogate learns to predict the output sequence from the input sequence. During training, the model minimizes the mean-squared error (MSE) between its predictions and the true simulation output.\n",
    "\n",
    "Below is the code for the dataset definition, model definitions, training loop, and prediction plotting. \n",
    "\n",
    "The training process uses mixed precision (via `torch.cuda.amp`) for efficiency and includes learning rate scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df95edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------- #\n",
    "# 6. DLS Surrogate Training\n",
    "# -------------------------------------------------------- #\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "##############################################################################\n",
    "# 0. Dataset Definition with Data Scaling\n",
    "##############################################################################\n",
    "\n",
    "class SEIRTimeSeriesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Expects a list of tuples (params, output). For each sample, creates an input sequence X of shape (T, 10) where:\n",
    "      - Column 0: normalized time feature (values between 0 and 1)\n",
    "      - Columns 1-10: 9-dimensional parameter vector repeated at each time step\n",
    "    The target Y is the total incidence time series (reshaped to (T, 1)).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, results_list, x_scaler=None, y_scaler=None):\n",
    "        self.samples = []\n",
    "        self.seq_len = None\n",
    "        self.x_scaler = x_scaler\n",
    "        self.y_scaler = y_scaler\n",
    "        for params, output in results_list:\n",
    "            p = np.array([\n",
    "                params[\"latent_period\"],\n",
    "                params[\"infectious_period\"],\n",
    "                params[\"immunity_period\"]\n",
    "            ] + params[\"Rt\"] + params[\"tt_Rt\"], dtype=np.float32)\n",
    "            y = np.array(output[\"total_incidence\"], dtype=np.float32)\n",
    "            if self.seq_len is None:\n",
    "                self.seq_len = len(y)\n",
    "            else:\n",
    "                assert len(y) == self.seq_len, \"All sequences must have the same length.\"\n",
    "            self.samples.append((p, y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, y = self.samples[idx]\n",
    "        T = self.seq_len\n",
    "        time_feature = np.linspace(0, 1, T).reshape(T, 1).astype(np.float32)\n",
    "        p_repeated = np.tile(p, (T, 1))\n",
    "        X = np.concatenate([time_feature, p_repeated], axis=1)\n",
    "        if self.x_scaler is not None:\n",
    "            scaled_params = self.x_scaler.transform(p.reshape(1, -1))\n",
    "            scaled_params = np.tile(scaled_params, (T, 1))\n",
    "            X[:, 1:] = scaled_params\n",
    "        if self.y_scaler is not None:\n",
    "            y = self.y_scaler.transform(y.reshape(-1, 1)).reshape(-1)\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "##############################################################################\n",
    "# 1. Model Definitions: LSTM and GRU\n",
    "##############################################################################\n",
    "\n",
    "class SEIRLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2, dropout_prob=0.1):\n",
    "        super(SEIRLSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout_prob if num_layers > 1 else 0.0,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.ln = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.ln(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "class SEIRGRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2, dropout_prob=0.1):\n",
    "        super(SEIRGRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout_prob if num_layers > 1 else 0.0,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.ln = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.ln(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "##############################################################################\n",
    "# 2. Training Function\n",
    "##############################################################################\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs, optimizer, scheduler, device):\n",
    "    criterion = nn.MSELoss()\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        for X, Y in train_loader:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                pred = model(X)\n",
    "                loss = criterion(pred, Y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch}: Train Loss = {avg_train_loss:.4f} | Duration: {time.time()-epoch_start:.2f}s\")\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_val, Y_val in val_loader:\n",
    "                X_val = X_val.to(device)\n",
    "                Y_val = Y_val.to(device)\n",
    "                with autocast():\n",
    "                    pred_val = model(X_val)\n",
    "                    loss_val = criterion(pred_val, Y_val)\n",
    "                total_val_loss += loss_val.item()\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print(f\"          Val Loss   = {avg_val_loss:.4f}\")\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(avg_train_loss)\n",
    "\n",
    "##############################################################################\n",
    "# 3. Prediction Plotting Function (Side by Side for LSTM and GRU)\n",
    "##############################################################################\n",
    "\n",
    "def plot_predictions(model_lstm, model_gru, dataset, device, y_scaler, n_samples=5):\n",
    "    model_lstm.eval()\n",
    "    model_gru.eval()\n",
    "    indices = np.random.choice(len(dataset), n_samples, replace=False)\n",
    "\n",
    "    n_cols = 5\n",
    "    n_rows = math.ceil(n_samples / n_cols)\n",
    "\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 3 * n_rows))\n",
    "    if n_rows * n_cols == 1:\n",
    "        axs = [axs]\n",
    "    else:\n",
    "        axs = axs.flatten()\n",
    "\n",
    "    for ax in axs[n_samples:]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        X, Y = dataset[idx]\n",
    "        X = X.unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            pred_lstm = model_lstm(X)\n",
    "            pred_gru = model_gru(X)\n",
    "\n",
    "        pred_lstm = pred_lstm.squeeze(0).cpu().numpy()\n",
    "        pred_gru = pred_gru.squeeze(0).cpu().numpy()\n",
    "        Y = Y.squeeze(1).cpu().numpy()\n",
    "\n",
    "        pred_lstm_orig = y_scaler.inverse_transform(pred_lstm)\n",
    "        pred_gru_orig = y_scaler.inverse_transform(pred_gru)\n",
    "        Y_orig = y_scaler.inverse_transform(Y.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "        ax = axs[i]\n",
    "        ax.plot(Y_orig, label=\"Ground Truth\", color=\"black\")\n",
    "        ax.plot(pred_lstm_orig, label=\"LSTM\", linestyle=\"--\", color=\"blue\")\n",
    "        ax.plot(pred_gru_orig, label=\"GRU\", linestyle=\":\", color=\"red\")\n",
    "        ax.set_title(f\"Sample {idx}\")\n",
    "        ax.set_xlabel(\"Time Step\")\n",
    "        ax.set_ylabel(\"Total Incidence\")\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "##############################################################################\n",
    "# 5. Main Script for Surrogate Training\n",
    "##############################################################################\n",
    "\n",
    "train_params = np.array([\n",
    "    np.array([\n",
    "        p[\"latent_period\"], p[\"infectious_period\"], p[\"immunity_period\"]\n",
    "    ] + p[\"Rt\"] + p[\"tt_Rt\"])\n",
    "    for (p, o) in train_results\n",
    "], dtype=np.float32)\n",
    "\n",
    "x_scaler = StandardScaler().fit(train_params)\n",
    "\n",
    "train_targets = np.array([\n",
    "    o[\"total_incidence\"] for (p, o) in train_results\n",
    "], dtype=np.float32)\n",
    "y_scaler = StandardScaler().fit(train_targets.reshape(-1, 1))\n",
    "\n",
    "train_dataset = SEIRTimeSeriesDataset(train_results, x_scaler=x_scaler, y_scaler=y_scaler)\n",
    "val_dataset = SEIRTimeSeriesDataset(test_results, x_scaler=x_scaler, y_scaler=y_scaler)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size = 10  \n",
    "hidden_size = 128\n",
    "output_size = 1\n",
    "num_layers = 2\n",
    "dropout_prob = 0.05\n",
    "\n",
    "# Create both LSTM and GRU models\n",
    "model_lstm = SEIRLSTMModel(input_size, hidden_size, output_size, num_layers, dropout_prob).to(device)\n",
    "model_gru = SEIRGRUModel(input_size, hidden_size, output_size, num_layers, dropout_prob).to(device)\n",
    "\n",
    "optimizer_lstm = optim.Adam(model_lstm.parameters(), lr=1e-3)\n",
    "scheduler_lstm = optim.lr_scheduler.StepLR(optimizer_lstm, step_size=10, gamma=0.5)\n",
    "\n",
    "optimizer_gru = optim.Adam(model_gru.parameters(), lr=1e-3)\n",
    "scheduler_gru = optim.lr_scheduler.StepLR(optimizer_gru, step_size=10, gamma=0.5)\n",
    "\n",
    "epochs = 300\n",
    "print(\"Training LSTM model...\")\n",
    "train_model(model_lstm, train_loader, val_loader, epochs, optimizer_lstm, scheduler_lstm, device)\n",
    "print(\"Training GRU model...\")\n",
    "train_model(model_gru, train_loader, val_loader, epochs, optimizer_gru, scheduler_gru, device)\n",
    "\n",
    "plot_predictions(model_lstm, model_gru, val_dataset, device, y_scaler, n_samples=5)\n",
    "\n",
    "# Evaluate on additional test samples\n",
    "for i in range(10):\n",
    "    n_samples = 5\n",
    "    test_results = sample_and_run_models(n_samples, contact_matrix, N, I0, t_end,\n",
    "                                          latent_range, infectious_range, immunity_range,\n",
    "                                          Rt_range, tt_Rt_range, dt=0.1)\n",
    "    val_dataset = SEIRTimeSeriesDataset(test_results, x_scaler=x_scaler, y_scaler=y_scaler)\n",
    "    batch_size = 32\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    plot_predictions(model_lstm, model_gru, val_dataset, device, y_scaler, n_samples=n_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d8d7f7",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook we:\n",
    "\n",
    "- Introduced the theory behind infectious disease (ID) modelling with the SEIR compartmental framework.\n",
    "- Discussed the benefits of surrogate models to approximate expensive simulations.\n",
    "- Reviewed the basics of RNNs and provided detailed equations for LSTM and GRU cells.\n",
    "- Demonstrated parameter exploration using Latin Hypercube Sampling (LHS).\n",
    "- Trained and compared two surrogate models (one based on LSTM and one on GRU) to predict the SEIR simulation output.\n",
    "\n",
    "This integrated approach can be extended to other epidemiological models and serves as a foundation for rapid prediction and uncertainty quantification in infectious disease dynamics.\n",
    "\n",
    "Feel free to modify and expand upon this notebook for your research or teaching needs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
